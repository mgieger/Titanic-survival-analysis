Macknezie's note:
    Before normalization/standardization attempts: accuracy was low 70.05%
    Attempting to use MinMaScalar to standardize the data and hte accuracy dropped to 50%
    Accuracy is now at 71.71% using default decision tree using sklern Normalizer()


Random Experiment Results:  -- No real strategy employed -- just tried to experiment with
the different parameters to see what type of effect they had on the decision tree


Estimators and random state = 0

perm 1 est = 4
[0.09916565 0.12530482 0.39415205 0.16364373 0.05201302 0.
 0.16572072]
0.7092337917485265


perm 1 est = 4
[0.09360033 0.13957649 0.38616546 0.16734597 0.0444947  0.
 0.16881706]
0.6777996070726916


perm 1 est = 10,
[0.11044275 0.14889277 0.34170025 0.16396146 0.05457189 0.
 0.18043088]
0.7131630648330058

perm 1 est = 25
[0.11233163 0.15745226 0.33987244 0.1599026  0.05204276 0.
 0.17839831]
0.6679764243614931

perm 1 est = 10
[0.11085853 0.15304792 0.33158263 0.16852518 0.04992043 0.
 0.18606531]
0.7170923379174853


Depth change:
perm 1 depth = 2
[0.13175326 0.24904745 0.27467061 0.09887683 0.         0.
 0.24565185]
0.7269155206286837


perm 1 depth = 3
[0.08201113 0.13085522 0.51035563 0.0649718  0.01451032 0.
 0.19729591]
0.7465618860510805
perm 1 depth  =4

[0.06115844 0.15925786 0.51956454 0.0749426  0.02124436 0.
 0.16383221]
0.7328094302554028

perm 1 depth = 6
[0.11287249 0.14886972 0.46593474 0.07838467 0.02731952 0.
 0.16661886]
0.6817288801571709


perm 1 default
    data_perm_1 = preprocessor.get_matrix_split(['sex', 'age', 'ticket', 'fare', 'pclass', 'name', 'sibsp', 'parch',  'embarked', 'survived']) #2
[0.30135055 0.15235566 0.03510052 0.16140203 0.08043203 0.12259867
 0.04684617 0.05373585 0.04617852]
0.7131630648330058

tree perm 2
    data_perm_2 = preprocessor.get_matrix_split(['sex', 'age', 'ticket', 'fare', 'pclass', 'name',  'sibsp', 'parch',  'survived'])
[0.37531511 0.14752843 0.03243399 0.15935525 0.09124312 0.10201355
 0.04793405 0.04417649]
0.7072691552062869

tree perm 3
    data_perm_3 = preprocessor.get_matrix_split(['pclass', 'name', 'sex', 'age', 'ticket', 'cabin', 'fare', 'survived'])
[0.11085853 0.15304792 0.33158263 0.16852518 0.04992043 0.
 0.18606531]
0.7170923379174853

tree perm  4
    data_perm_4 = preprocessor.get_matrix_split(['sex', 'age', 'ticket', 'fare','cabin', 'survived'])
[0.43091254 0.22544028 0.07176697 0.27188021 0.        ]
0.7111984282907662

tree perm 5
    data_perm_5 = preprocessor.get_matrix_split(['sex', 'age', 'ticket', 'fare', 'survived'])  #2
[0.4420839  0.23431854 0.07386514 0.24973242]
0.730844793713163

tree perm 6
    data_perm_6 = preprocessor.get_matrix_split(['name', 'age', 'ticket', 'fare', 'survived'])  #2
[0.36563852 0.23349556 0.0675253  0.33334061]
0.7092337917485265

tree perm 7
    data_perm_7 = preprocessor.get_matrix_split(['sex', 'age', 'ticket', 'survived'])
[0.57195409 0.33513911 0.0929068 ]
0.7111984282907662

tree perm 8
    data_perm_8 = preprocessor.get_matrix_split(['sex', 'age', 'fare', 'survived'])
[0.367178   0.33240278 0.30041922]
0.6797642436149313

tree perm 9
    data_perm_9 = preprocessor.get_matrix_split(['sex', 'age', 'survived']) # 1) best b4 tuning - but two parameters seems useless
[0.46330532 0.53669468]
0.7445972495088409

tree perm 10
    data_perm_10 = preprocessor.get_matrix_split(['sex', 'age', 'fare', 'name','survived'])
[0.38282366 0.1791181  0.1841852  0.25387304]
0.6797642436149313

perm 1 warm
[0.34430334 0.14013477 0.03684195 0.15718217 0.09115979 0.11423987
 0.04035948 0.0279463  0.04783232]
0.693516699410609

perm 1 gradient boost forest
[0.8571583  0.00882428 0.         0.         0.         0.10790864
 0.         0.02610878 0.        ]
0.7465618860510805

perm 1 random
[0.34067706 0.14592974 0.03516259 0.13891063 0.07987614 0.12675852
 0.03530035 0.05916527 0.03821969]
0.6699410609037328

perm 1 est
[0.30135055 0.15235566 0.03510052 0.16140203 0.08043203 0.12259867
 0.04684617 0.05373585 0.04617852]
0.7131630648330058

perm 1 depth
[0.5674818  0.04086865 0.00372413 0.13940479 0.02367137 0.06257128
 0.04764439 0.08878574 0.02584784]
0.7347740667976425

perm 1 combo 1
[0.55766122 0.04540961 0.00413793 0.13367372 0.02630152 0.05671096
 0.05293821 0.09444701 0.02871982]
0.724950884086444


[0.55356296 0.02434531 0.01166023 0.17224872 0.0531627  0.09109564
 0.0072345  0.08668994]
0.7131630648330058


[0.07947096 0.12995853 0.49610234 0.06296306 0.01228744 0.
 0.21921768]
0.7485265225933202


[0.78707354 0.06587172 0.01359923 0.13345552 0.        ]
0.7603143418467584


[0.7855387  0.05483171 0.00987686 0.14975273]
0.7445972495088409


[0.38936458 0.08039    0.0513861  0.47885932]
0.6660117878192534


[0.60354563 0.27777989 0.11867448]
0.7445972495088409


[0.41951697 0.29287459 0.28760844]
0.7013752455795678

 extreme random
[0.56469483 0.04552926 0.00413793 0.13165234 0.02486409 0.05678682
 0.05293821 0.09452449 0.02487203]
0.7387033398821218



